NAME
    agent.py - Implements a reinforcement learning agent to play the Snake game.

DESCRIPTION
    This module defines a reinforcement learning agent that uses a linear neural network
    to train itself in the Snake game. It includes functionalities to save and load checkpoints,
    manage the experience replay memory, and perform both short-term and long-term training.

FUNCTIONS
    load_memory(file_name='memory.pkl')
        Loads the experience replay memory from a pickle file.
        
        :param file_name: Name of the file from which the memory will be loaded.
        :return: A deque object containing the loaded memory.

    save_memory(memory, file_name='memory.pkl')
        Saves the experience replay memory to a pickle file.
        
        :param memory: A deque object containing the experience replay memory.
        :param file_name: Name of the file where the memory will be saved.

    train()
        Trains the agent by playing multiple games of Snake.
        
        Periodically saves checkpoints and records statistics such as scores,
        explorations, and exploitations. Generates progress graphs and saves them as files.

CLASSES
    Agent
        Represents the reinforcement learning agent that interacts with the game environment.
        
        Methods defined here:
        
        __init__(self)
            Initializes the agent with exploration/exploitation parameters, experience replay memory,
            a neural network model, and a trainer.
        
        get_action(self, state)
            Decides the action to take based on the current state.
            
            :param state: Current state of the game.
            :return: Action encoded as a one-hot vector.
        
        get_state(self, game)
            Retrieves the current state of the game as a binary vector.
            
            :param game: Instance of the SnakeGameAI game.
            :return: A numpy array representing the state of the game.
        
        load_checkpoint(self, file_name='checkpoint.pth')
            Loads the previous state of the model, optimizer, number of games, and experience replay memory.
        
        remember(self, state, action, reward, next_state, done)
            Stores a transition in the experience replay memory.
            
            :param state: Current state.
            :param action: Action taken.
            :param reward: Reward obtained.
            :param next_state: Next state.
            :param done: Indicates whether the episode has ended.
        
        save_checkpoint(self, file_name='checkpoint.pth')
            Saves the current state of the model, optimizer, number of games, and experience replay memory.
        
        train_long_memory(self)
            Trains the model using a random subset of the experience replay memory.
        
        train_short_memory(self, state, action, reward, next_state, done)
            Trains the model with a single transition.

DATA
    BATCH_SIZE = 1000
    LR = 0.002
    MAX_MEMORY = 100000

FILE
    /path/to/file/ejemplo.py